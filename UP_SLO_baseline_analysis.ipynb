{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21d30864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import regex as re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from openpyxl import load_workbook\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50e6d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/arvind/Documents/Work/Zoho WorkDrive (Educational Initiatives Private Limited)/My Folders/Projects/CSF/Analysis/Code/DQA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce87b4",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Import raw data files\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98213e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_raw = pd.read_excel(\"./2022_11_08_up_raw_literacy_cleaned.xlsx\", index_col=[0])\n",
    "numeracy_raw = pd.read_excel(\"./2022_11_08_up_raw_numeracy_cleaned.xlsx\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5053c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_score(scores):\n",
    "    total_score = 0\n",
    "    for score in scores:\n",
    "        if score == 1:\n",
    "            total_score += 1\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ee1a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_info =['tabletUserName', 'assessment_date', 'school_details.State_label', 'school_details.District_label', \\\n",
    "               'school_details.Block_label', 'school_details.School_label', 'school_details.UDISE_cd_label']\n",
    "\n",
    "student_info = ['SI_std_name', 'student_age', 'student_gender']\n",
    "\n",
    "up_lit_scores = literacy_raw[general_info + student_info].set_index(literacy_raw.index)\n",
    "up_num_scores = numeracy_raw[general_info + student_info].set_index(numeracy_raw.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30efec0c",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">\n",
    "    Literary Sub-task Score Calculations\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f1080",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 1: Listening Comprehension\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7571b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate total score on listening comprehension sub-task\n",
    "literacy1 = [col for col in literacy_raw.columns if re.search(r'literacy1_q\\d$', col)]\n",
    "                                                         \n",
    "up_lit_scores.loc[:, 'literacy1_total'] = literacy_raw.apply(lambda x: total_score([x[col] for col in literacy1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aab95a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract other responses to oral vocabulary questions\n",
    "literacy1_or = [col for col in literacy_raw.columns if re.search(r'literacy1\\S*or$', col)]\n",
    "with pd.ExcelWriter('literacy1_other_responses.xlsx') as writer: \n",
    "    for col in literacy1_or:\n",
    "        literacy_raw[col].value_counts().reset_index().rename(columns = {'index':\"Child's response\", col:'Frequency'}).to_excel(writer, sheet_name=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a736f5",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 2: Oral Vocabulary\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9c7c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total score on oral comprehension sub-task\n",
    "literacy2 = [col for col in literacy_raw.columns if re.search(r'literacy2_q\\d+$', col)]\n",
    "                                                         \n",
    "up_lit_scores.loc[:, 'literacy2_total'] = literacy_raw.apply(lambda x: total_score([x[col] for col in literacy2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9e63b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract other responses to oral vocabulary questions\n",
    "literacy2_or = [col for col in literacy_raw.columns if re.search(r'literacy2\\S*or$', col)]\n",
    "with pd.ExcelWriter('literacy2_other_responses.xlsx') as writer: \n",
    "    for col in literacy2_or:\n",
    "        literacy_raw[col].value_counts().reset_index().rename(columns = {'index':\"Child's response\", col:'Frequency'}).to_excel(writer, sheet_name=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb1640",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 3: Initial Sound Identification\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "368e4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total score on initial sound identification sub-task\n",
    "literacy3 = [col for col in literacy_raw.columns if re.search(r'literacy3_q+', col)]\n",
    "                                                         \n",
    "up_lit_scores.loc[:, 'literacy3_total'] = literacy_raw.apply(lambda x: total_score([x[col] for col in literacy3]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053b35e",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 4: Letter Recognition (Untimed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b505c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy4_ut = [col for col in literacy_raw.columns if re.search(r'literacy4_ut_grid_\\d*$', col)]\n",
    "    \n",
    "# Calculate total score on letter naming (untimed) sub-task\n",
    "up_lit_scores.loc[:, 'literacy4_ut_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy4_ut]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e17d3a",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 4: Letter Recognition (Timed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0477408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy4_tt =  [col for col in literacy_raw.columns if re.search(r'literacy4_tt_grid_\\d*$', col)]\n",
    "\n",
    "# Calculate total score on letter naming (timed) sub-task\n",
    "up_lit_scores.loc[:, 'literacy4_tt_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy4_tt]), axis=1)\n",
    "up_lit_scores.loc[:, 'literacy4_tt_time_taken'] = np.where(literacy_raw['literacy4_tt_grid.time_remaining']!='UNDEFINED',literacy_raw['literacy4_tt_grid.time_remaining'],60)\n",
    "up_lit_scores['literacy4_tt_time_taken']= 60 - pd.to_numeric(up_lit_scores['literacy4_tt_time_taken'],errors='coerce').convert_dtypes()\n",
    "up_lit_scores.loc[:,'literacy4_tt_cpm'] = np.where(np.logical_or(up_lit_scores['literacy4_tt_total']==0, up_lit_scores['literacy4_tt_time_taken']==0),0,round(60*up_lit_scores['literacy4_tt_total']/up_lit_scores['literacy4_tt_time_taken'],0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb1485",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 5: Familiar Words Reading (Untimed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc0798ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy5_ut = [col for col in literacy_raw.columns if re.search(r'literacy5_ut_grid_\\d*$', col)]\n",
    "    \n",
    "up_lit_scores.loc[:, 'literacy5_ut_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy5_ut]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278617b",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 5: Familiar Words Reading (Timed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2be34045",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy5_tt = [col for col in literacy_raw.columns if re.search(r'literacy5_tt_grid_\\d*$', col)]\n",
    "\n",
    "up_lit_scores.loc[:, 'literacy5_tt_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy5_tt]), axis=1)\n",
    "up_lit_scores.loc[:, 'literacy5_tt_time_taken'] = np.where(literacy_raw['literacy5_tt_grid.time_remaining']!='UNDEFINED',literacy_raw['literacy5_tt_grid.time_remaining'],60)\n",
    "up_lit_scores['literacy5_tt_time_taken']= 60 - pd.to_numeric(up_lit_scores['literacy5_tt_time_taken'],errors='coerce').convert_dtypes()\n",
    "up_lit_scores.loc[:,'literacy5_tt_cpm'] = np.where(np.logical_or(up_lit_scores['literacy5_tt_total']==0, up_lit_scores['literacy5_tt_time_taken']==0),0,round(60*up_lit_scores['literacy5_tt_total']/up_lit_scores['literacy5_tt_time_taken'],0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c497785",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 6: Non-word Reading\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ac0c46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy6 = [col for col in literacy_raw.columns if re.search(r'literacy6_tt_grid_\\d*$', col)]\n",
    "\n",
    "up_lit_scores.loc[:, 'literacy6_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy6]), axis=1)\n",
    "up_lit_scores.loc[:, 'literacy6_tt_time_taken'] = np.where(literacy_raw['literacy6_tt_grid.time_remaining']!='UNDEFINED',literacy_raw['literacy6_tt_grid.time_remaining'],60)\n",
    "up_lit_scores['literacy6_tt_time_taken']= 60 - pd.to_numeric(up_lit_scores['literacy6_tt_time_taken'],errors='coerce').convert_dtypes()\n",
    "up_lit_scores.loc[:,'literacy6_tt_cpm'] = np.where(np.logical_or(up_lit_scores['literacy6_total']==0, up_lit_scores['literacy6_tt_time_taken']==0),0,round(60*up_lit_scores['literacy6_total']/up_lit_scores['literacy6_tt_time_taken'],0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4b09a",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 7: Oral Reading Fluency (Timed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59079383",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy7 = [col for col in literacy_raw.columns if re.search(r'literacy7_tt_grid_\\d*$', col)]\n",
    "\n",
    "up_lit_scores.loc[:, 'literacy7_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy7]), axis=1)\n",
    "up_lit_scores.loc[:, 'literacy7_tt_time_taken'] = np.where(literacy_raw['literacy7_tt_grid.time_remaining']!='UNDEFINED',literacy_raw['literacy7_tt_grid.time_remaining'],60)\n",
    "up_lit_scores['literacy7_tt_time_taken']= 60 - pd.to_numeric(up_lit_scores['literacy7_tt_time_taken'],errors='coerce').convert_dtypes()\n",
    "up_lit_scores.loc[:,'literacy7_tt_cpm'] = np.where(np.logical_or(up_lit_scores['literacy7_total']==0, up_lit_scores['literacy7_tt_time_taken']==0),0,round(60*up_lit_scores['literacy7_total']/up_lit_scores['literacy7_tt_time_taken'],0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3d5ae",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 8: Reading Comprehension (Untimed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee8762c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy8_reading = [col for col in literacy_raw.columns if re.search(r'literacy8_ut_grid_\\d*$', col)]\n",
    "\n",
    "literacy8_comprehension = [col for col in literacy_raw.columns if re.search(r'literacy8_ut_q\\d*$', col)]\n",
    "\n",
    "up_lit_scores.loc[:, 'literacy8_reading_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy8_reading]), axis=1)\n",
    "\n",
    "up_lit_scores.loc[:, 'literacy8_comprehension_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy8_comprehension]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83368fd",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 9a: Dictation (Letters)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed37c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy9a = [col for col in literacy_raw.columns if re.search(r'literacy9a_ut_grid_\\d*$', col)]\n",
    "\n",
    "up_lit_scores.loc[:, 'literacy9a_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy9a]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83bd5c9",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Literacy 9a: Dictation (Words)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43c2e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy9b = [col for col in literacy_raw.columns if re.search(r'literacy9b_ut_grid_\\d*$', col)]\n",
    "\n",
    "up_lit_scores.loc[:, 'literacy9b_total'] = literacy_raw.apply(lambda x: total_score([x[score] for score in literacy9b]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0ac6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_lit_scores.to_excel(datetime.now().strftime(\"%Y_%m_%d\")+\"_up_literacy_total_scores.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b549c",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    B. Numeracy Sub-tasks Data Cleaning\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe0a1e",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 1: Counting\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d2475ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate total score on counting sub-task\n",
    "numeracy1 = [col for col in numeracy_raw.columns if re.search(r'numeracy1_tt_grid_\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy1_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy1]), axis=1)\n",
    "up_num_scores.loc[:, 'numeracy1_tt_time_taken'] = np.where(numeracy_raw['numeracy1_tt_grid.time_remaining']!='UNDEFINED',numeracy_raw['numeracy1_tt_grid.time_remaining'],60)\n",
    "up_num_scores['numeracy1_tt_time_taken']= 60 - pd.to_numeric(up_num_scores['numeracy1_tt_time_taken'],errors='coerce').convert_dtypes()\n",
    "up_num_scores.loc[:,'numeracy1_tt_cpm'] = np.where(np.logical_or(up_num_scores['numeracy1_total']==0, up_num_scores['numeracy1_tt_time_taken']==0),0,round(60*up_num_scores['numeracy1_total']/up_num_scores['numeracy1_tt_time_taken'],0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d9189",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 2: Number Recognition (Untimed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4741f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy2_ut = [col for col in numeracy_raw.columns if re.search(r'numeracy2_ut_grid_\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy2_ut_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy2_ut]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c07586",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 2: Number Recognition (Timed)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed362e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy2_tt = [col for col in numeracy_raw.columns if re.search(r'numeracy2_tt_grid_\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy2_tt_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy2_tt]), axis=1)\n",
    "up_num_scores.loc[:, 'numeracy2_tt_time_taken'] = np.where(numeracy_raw['numeracy2_tt_grid.time_remaining']!='UNDEFINED',numeracy_raw['numeracy2_tt_grid.time_remaining'],60)\n",
    "up_num_scores['numeracy2_tt_time_taken']= 60 - pd.to_numeric(up_num_scores['numeracy2_tt_time_taken'],errors='coerce').convert_dtypes()\n",
    "up_num_scores.loc[:,'numeracy2_tt_cpm'] = np.where(np.logical_or(up_num_scores['numeracy2_tt_total']==0, up_num_scores['numeracy2_tt_time_taken']==0),0,round(60*up_num_scores['numeracy2_tt_total']/up_num_scores['numeracy2_tt_time_taken'],0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668629a",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 3: Number Comparison\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c474b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy3 = [col for col in numeracy_raw.columns if re.search(r'numeracy3\\w*', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy3_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy3]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6964e",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 4: Counting in Bundles\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1947fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy4 = [col for col in numeracy_raw.columns if re.search(r'numeracy4_ut_q\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy4_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy4]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9986f",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 5: Missing Numbers\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7313c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy5 = [col for col in numeracy_raw.columns if re.search(r'numeracy5_ut_q\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy5_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy5]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919dd600",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 6: Addition\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "00f59ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy6 = [col for col in numeracy_raw.columns if re.search(r'numeracy6_ut_q\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy6_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy6]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1f7d2",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 7: Subtraction\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2f45dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy7 = [col for col in numeracy_raw.columns if re.search(r'numeracy7_ut_q\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy7_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy7]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26fed70",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 8: Word Problems\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8fe9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy8 = [col for col in numeracy_raw.columns if re.search(r'numeracy8_ut_q\\d*$', col)]\n",
    "\n",
    "up_num_scores.loc[:, 'numeracy8_total'] = numeracy_raw.apply(lambda x: total_score([x[col] for col in numeracy8]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9435b",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 9a: Shape Recognition (Circle)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03a967e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy9a = [col for col in numeracy_raw.columns if re.search(r'numeracy9a_ut_grid_\\d$', col)]\n",
    "\n",
    "def total_score_9a(scores):\n",
    "    total_score_9a = 0\n",
    "    if scores[0] == '1' and scores[1] == '1' and scores[2] == '0' and scores[3] == '1' and scores[4] == '1' and scores[5] == '1' and scores[6] == '1' and scores[7] == '0':\n",
    "            total_score_9a += 1 \n",
    "    return total_score_9a\n",
    "    \n",
    "up_num_scores.loc[:, 'numeracy9a_total'] = numeracy_raw.apply(lambda x: total_score_9a([x[score] for score in numeracy9a]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c29c4c",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Numeracy 9b: Shape Recognition (Rectangle)\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "724d18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy9b = [col for col in numeracy_raw.columns if re.search(r'numeracy9b_ut_grid_\\d$', col)]\n",
    "    \n",
    "def total_score_9b(scores):\n",
    "    total_score_9b = 0\n",
    "    if scores[0] == '1' and scores[1] == '0' and scores[2] == '1' and scores[3] == '1' and scores[4] == '0' and scores[5] == '1' and scores[6] == '1' and scores[7] == '0':\n",
    "            total_score_9b += 1 \n",
    "    return total_score_9b   \n",
    "    \n",
    "up_num_scores.loc[:, 'numeracy9b_total'] = numeracy_raw.apply(lambda x: total_score_9b([x[score] for score in numeracy9b]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f83dab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_num_scores.to_excel(datetime.now().strftime(\"%Y_%m_%d\")+\"_up_numeracy_total_scores.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
