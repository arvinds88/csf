{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21d30864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import regex as re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from openpyxl import load_workbook\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05b10dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/arvind/Documents/Work/Zoho WorkDrive (Educational Initiatives Private Limited)/My Folders/Projects/CSF/Analysis/Code/DQA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce87b4",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Import raw data files\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98213e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all scored files\n",
    "mp_literacy_scored = pd.read_excel(\"./2022_11_08_mp_literacy_total_scores.xlsx\", index_col=[0])\n",
    "mp_numeracy_scored = pd.read_excel(\"./2022_11_08_mp_numeracy_total_scores.xlsx\", index_col=[0])\n",
    "up_literacy_scored = pd.read_excel(\"./2022_11_08_up_literacy_total_scores.xlsx\", index_col=[0])\n",
    "up_numeracy_scored = pd.read_excel(\"./2022_11_08_up_numeracy_total_scores.xlsx\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3d05774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(col in up_literacy_scored.columns for col in mp_literacy_scored.columns)\n",
    "all(col in up_numeracy_scored.columns for col in mp_numeracy_scored.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "487ca779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging state files\n",
    "literacy_scored = pd.concat([mp_literacy_scored,up_literacy_scored],join='inner')\n",
    "numeracy_scored = pd.concat([mp_numeracy_scored,up_numeracy_scored],join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0bf802da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Madhya Pradesh', 'Madhya_Pradesh', 'Uttar Pradesh',\n",
       "       'Uttar_Pradesh'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literacy_scored['school_details.State_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6e2143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_scored['school_details.State_label'] = literacy_scored['school_details.State_label'].replace('Madhya_Pradesh','Madhya Pradesh')\n",
    "literacy_scored['school_details.State_label'] = literacy_scored['school_details.State_label'].replace('Uttar_Pradesh','Uttar Pradesh')\n",
    "numeracy_scored['school_details.State_label'] = numeracy_scored['school_details.State_label'].replace('Madhya_Pradesh','Madhya Pradesh')\n",
    "numeracy_scored['school_details.State_label'] = numeracy_scored['school_details.State_label'].replace('Uttar_Pradesh','Uttar Pradesh')\n",
    "                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "960b409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output for Tableau Workbook\n",
    "literacy_scored.to_excel(\"../Results/literacy_scored.xlsx\")\n",
    "numeracy_scored.to_excel(\"../Results/numeracy_scored.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62451e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tabletUserName',\n",
       " 'assessment_date',\n",
       " 'school_details.State_label',\n",
       " 'school_details.District_label',\n",
       " 'school_details.Block_label',\n",
       " 'school_details.School_label',\n",
       " 'school_details.UDISE_cd_label',\n",
       " 'SI_std_name',\n",
       " 'student_age',\n",
       " 'student_gender',\n",
       " 'literacy1_total',\n",
       " 'literacy2_total',\n",
       " 'literacy3_total',\n",
       " 'literacy4_ut_total',\n",
       " 'literacy4_tt_total',\n",
       " 'literacy4_tt_time_taken',\n",
       " 'literacy4_tt_cpm',\n",
       " 'literacy5_ut_total',\n",
       " 'literacy5_tt_total',\n",
       " 'literacy5_tt_time_taken',\n",
       " 'literacy5_tt_cpm',\n",
       " 'literacy6_total',\n",
       " 'literacy6_tt_time_taken',\n",
       " 'literacy6_tt_cpm',\n",
       " 'literacy7_total',\n",
       " 'literacy7_tt_time_taken',\n",
       " 'literacy7_tt_cpm',\n",
       " 'literacy8_reading_total',\n",
       " 'literacy8_comprehension_total',\n",
       " 'literacy9a_total',\n",
       " 'literacy9b_total']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literacy_scored.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2153355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_gender\n",
       "Female    23\n",
       "Male      71\n",
       "Name: literacy8_comprehension_total, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literacy_scored.groupby(['student_gender'])['literacy8_comprehension_total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe00588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming variables for ease and use in R\n",
    "literacy_scored = literacy_scored.rename(columns = {'school_details.State_label':'State',\n",
    "                                  'school_details.District_label':'District',\n",
    "                                  'school_details.Block_label':'Block',\n",
    "                                  'school_details.School_label':'School',\n",
    "                                  'school_details.UDISE_cd_label':'UDISE',\n",
    "                                  'SI_std_name':'Name',\n",
    "                                  'student_age':'Age',\n",
    "                                  'student_gender':'Gender'})\n",
    "numeracy_scored = numeracy_scored.rename(columns = {'school_details.State_label':'State',\n",
    "                                  'school_details.District_label':'District',\n",
    "                                  'school_details.Block_label':'Block',\n",
    "                                  'school_details.School_label':'School',\n",
    "                                  'school_details.UDISE_cd_label':'UDISE',\n",
    "                                  'SI_std_name':'Name',\n",
    "                                  'student_age':'Age',\n",
    "                                  'student_gender':'Gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c161a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "literacy_scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd840468",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_scored['id'] = literacy_scored.index\n",
    "numeracy_scored['id'] = numeracy_scored.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba7bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i literacy_scored\n",
    "\n",
    "require(dplyr)\n",
    "require(Hmisc)\n",
    "require(sqldf)\n",
    "sqldf(\"select State, Gender, count(distinct id) as ct from literacy_scored group by State, Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for gender distribution\n",
    "literacy_scored.groupby(['State','Gender'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for student responses per school greater than 12\n",
    "chk1 = pd.DataFrame(literacy_scored.groupby(['UDISE'])['id'].count())\n",
    "chk1['UDISE'] = chk1.index\n",
    "chk1 = pd.DataFrame(chk1.groupby(['id'])['UDISE'].count())\n",
    "chk2 = pd.DataFrame(numeracy_scored.groupby(['UDISE'])['id'].count())\n",
    "chk2['UDISE'] = chk2.index\n",
    "chk2 = pd.DataFrame(chk2.groupby(['id'])['UDISE'].count())\n",
    "chk1.merge(chk2,how='left',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = pd.DataFrame(literacy_scored.groupby(['UDISE','Name','Age','Gender'])['id'].count())\n",
    "chk['UDISE'] = chk.index\n",
    "chk.groupby(['id'])['UDISE'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_scored[literacy_scored['literacy9b_total']>7].groupby(['State','District'])['Name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b16161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
